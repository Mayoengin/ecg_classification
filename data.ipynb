{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a47e9f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "from config import get_config\n",
    "from wfdb import rdrecord, rdann\n",
    "from scipy.signal import find_peaks\n",
    "import h5py\n",
    "from scipy.signal import find_peaks\n",
    "from sklearn.preprocessing import scale\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30ee778f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to dataset/train.hdf5 and dataset/trainlabel.hdf5.\n",
      "Data saved to dataset/test.hdf5 and dataset/testlabel.hdf5.\n"
     ]
    }
   ],
   "source": [
    "def ensure_directory_exists(file_path):\n",
    "    # Extracts the directory path from the given file path.\n",
    "    directory = os.path.dirname(file_path)\n",
    "    \n",
    "    # Checks if the directory does not exist.\n",
    "    if not os.path.exists(directory):\n",
    "        # Creates the directory along with any necessary intermediate directories.\n",
    "        os.makedirs(directory)\n",
    "\n",
    "def preprocess(split):\n",
    "    # List of numbers representing different ECG recordings or patients.\n",
    "    nums = ['100', '101', '102', '103', '104', '105', '106', '107', '108', '109',\n",
    "            '111', '112', '113', '114', '115', '116', '117', '118', '119',\n",
    "            '121', '122', '123', '124', '200', '201', '202', '203', '205',\n",
    "            '207', '208', '209', '210', '212', '213', '214', '215', '217', '219',\n",
    "            '220', '221', '222', '223', '228', '230', '231', '232', '233', '234']\n",
    "    \n",
    "    # List of ECG lead features to be considered in the dataset.\n",
    "    features = ['MLII', 'V1', 'V2', 'V3', 'V4', 'V5']\n",
    "    \n",
    "    # If 'split' is True, divide the data into training and testing sets.\n",
    "    if split:\n",
    "        # Define specific recordings as the test set.\n",
    "        testset = ['101', '105', '114', '118', '124', '201', '210', '217']\n",
    "        # The training set consists of all other recordings not in the test set.\n",
    "        trainset = [x for x in nums if x not in testset]\n",
    "        \n",
    "        # Process and save the training and test sets to HDF5 files.\n",
    "        dataSaver(trainset, 'dataset/train.hdf5', 'dataset/trainlabel.hdf5', features)\n",
    "        dataSaver(testset, 'dataset/test.hdf5', 'dataset/testlabel.hdf5', features)\n",
    "    else:\n",
    "        # For a single sample processing scenario.\n",
    "        num = 'sample_num'  \n",
    "        dataSaver(num, 'dataset/targetdata.hdf5', 'dataset/labeldata.hdf5', features)\n",
    "\n",
    "def dataSaver(dataSet, datasetname, labelsname, features):\n",
    "    classes = ['N', 'V', '/', 'A', 'F', '~']\n",
    "    Nclass = len(classes)\n",
    "    datadict, datalabel = {}, {}\n",
    "    n_class_counter = 0  # Counter for 'N' class instances\n",
    "\n",
    "    for feature in features:\n",
    "        datadict[feature] = []\n",
    "        datalabel[feature] = []\n",
    "\n",
    "def dataSaver(dataSet, datasetname, labelsname, features):\n",
    "    # List of ECG beat annotations to be classified.\n",
    "    classes = ['N', 'V', '/', 'A', 'F', '~']\n",
    "    # Total number of classes.\n",
    "    Nclass = len(classes)\n",
    "    # Dictionaries to hold the feature data and corresponding labels.\n",
    "    datadict, datalabel = {}, {}\n",
    "    # Counter for instances of the 'N' class (normal beats).\n",
    "    n_class_counter = 0\n",
    "    \n",
    "    for feature in features:\n",
    "        # Initialize lists to hold data and labels for each feature.\n",
    "        datadict[feature] = []\n",
    "        datalabel[feature] = []\n",
    "    \n",
    "    def dataprocess():\n",
    "        nonlocal n_class_counter  # Allows modification of 'n_class_counter' inside this function.\n",
    "        input_size = 256  # Size of the data window around each ECG beat.\n",
    "        for num in dataSet:\n",
    "            # Placeholder for actual data loading and preprocessing steps.\n",
    "            record = rdrecord('dataset/' + num, smooth_frames=True)\n",
    "            signals = scale(np.nan_to_num(record.p_signal), axis=0)\n",
    "            peaks, _ = find_peaks(signals[:, 0], distance=150)\n",
    "            \n",
    "            for peak in peaks[1:-1]:\n",
    "                start, end = peak - input_size // 2, peak + input_size // 2\n",
    "                if start < 0 or end > len(signals):\n",
    "                    continue  # Skip this segment if it goes out of bounds.\n",
    "                # Placeholder for annotation loading.\n",
    "                ann = rdann('dataset/' + num, extension='atr', sampfrom=start, sampto=end, return_label_elements=['symbol'])\n",
    "                annSymbol = ann.symbol\n",
    "                \n",
    "                # If the annotation is one of the specified classes.\n",
    "                if len(annSymbol) == 1 and (annSymbol[0] in classes):\n",
    "                    # Special handling for the 'N' class to prevent imbalance.\n",
    "                    if annSymbol[0] == 'N' and n_class_counter >= 20000:\n",
    "                        continue\n",
    "                    if annSymbol[0] == 'N':\n",
    "                        n_class_counter += 1\n",
    "                    \n",
    "                    # Create a one-hot encoded label for the annotation.\n",
    "                    y = [0] * Nclass\n",
    "                    y[classes.index(annSymbol[0])] = 1\n",
    "                    # Save the segment and its label for each feature.\n",
    "                    for feature_idx, feature in enumerate(features):\n",
    "                        if feature_idx < signals.shape[1]:  # Ensure feature index is valid.\n",
    "                            datadict[feature].append(signals[start:end, feature_idx])\n",
    "                            datalabel[feature].append(y)\n",
    "    \n",
    "    # Call the inner function to process data.\n",
    "    dataprocess()\n",
    "\n",
    "    # Convert lists to numpy arrays for efficient storage and manipulation.\n",
    "    for feature in features:\n",
    "        datadict[feature] = np.array(datadict[feature], dtype=np.float32)\n",
    "        datalabel[feature] = np.array(datalabel[feature], dtype=np.int32)\n",
    "\n",
    "    # Ensure the directories for the dataset and labels exist.\n",
    "    ensure_directory_exists(datasetname)\n",
    "    ensure_directory_exists(labelsname)\n",
    "    \n",
    "    # Save the processed data and labels to HDF5 files.\n",
    "    with h5py.File(datasetname, 'w') as hdf_file, h5py.File(labelsname, 'w') as label_file:\n",
    "        for feature in features:\n",
    "            hdf_file.create_dataset(feature, data=datadict[feature])\n",
    "            label_file.create_dataset(feature, data=datalabel[feature])\n",
    "    \n",
    "    print(f\"Data saved to {datasetname} and {labelsname}.\")\n",
    "def main(config):\n",
    "    # Call the preprocess function with the configuration provided.\n",
    "    preprocess(config.split)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Obtain configuration settings (not shown in your script).\n",
    "    config = get_config()\n",
    "    # Start the main function with the obtained configuration.\n",
    "    main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a9efd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
