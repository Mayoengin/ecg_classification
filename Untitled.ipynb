{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c9cbefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "from config import get_config\n",
    "from wfdb import rdrecord, rdann\n",
    "from scipy.signal import find_peaks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83bd991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_directory_exists(file_path):\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "def preprocess(split):\n",
    "    nums = ['100', '101', '102', '103', '104', '105', '106', '107', '108', '109',\n",
    "            '111', '112', '113', '114', '115', '116', '117', '118', '119',\n",
    "            '121', '122', '123', '124', '200', '201', '202', '203', '205',\n",
    "            '207', '208', '209', '210', '212', '213', '214', '215', '217', '219',\n",
    "            '220', '221', '222', '223', '228', '230', '231', '232', '233', '234']\n",
    "    \n",
    "    features = ['MLII', 'V1', 'V2', 'V3', 'V4', 'V5']\n",
    "    \n",
    "    if split:\n",
    "        testset = ['101', '105', '114', '118', '124', '201', '210', '217']\n",
    "        trainset = [x for x in nums if x not in testset]\n",
    "        \n",
    "        dataSaver(trainset, 'dataset/train.hdf5', 'dataset/trainlabel.hdf5', features)\n",
    "        dataSaver(testset, 'dataset/test.hdf5', 'dataset/testlabel.hdf5', features)\n",
    "    else:\n",
    "        num = 'sample_num'  \n",
    "        dataSaver(num, 'dataset/targetdata.hdf5', 'dataset/labeldata.hdf5', features)\n",
    "\n",
    "def dataSaver(dataSet, datasetname, labelsname, features):\n",
    "    print(\"Inside dataSaver\")\n",
    "\n",
    "    classes = ['N', 'V', '/', 'A', 'F', '~']\n",
    "    Nclass = len(classes)\n",
    "    datadict, datalabel = dict(), dict()\n",
    "\n",
    "    for feature in features:\n",
    "        datadict[feature] = list()\n",
    "        datalabel[feature] = list()\n",
    "\n",
    "    def dataprocess():\n",
    "            input_size = config.input_size\n",
    "            for num in tqdm(dataSet):\n",
    "                from wfdb import rdrecord, rdann\n",
    "                record = rdrecord('dataset/' + num, smooth_frames=True)\n",
    "                from sklearn import preprocessing\n",
    "                signals0 = preprocessing.scale(np.nan_to_num(record.p_signal[:, 0])).tolist()\n",
    "                signals1 = preprocessing.scale(np.nan_to_num(record.p_signal[:, 1])).tolist()\n",
    "                peaks, _ = find_peaks(signals0, distance=150)\n",
    "                feature0, feature1 = record.sig_name[0], record.sig_name[1]\n",
    "\n",
    "                for peak in peaks[1:-1]:\n",
    "                    start, end = peak - input_size // 2, peak + input_size // 2\n",
    "                    ann = rdann('dataset/' + num, extension='atr', sampfrom=start, sampto=end, return_label_elements=['symbol'])\n",
    "\n",
    "                    def to_dict(chosenSym):\n",
    "                        y = [0] * Nclass\n",
    "                        y[classes.index(chosenSym)] = 1\n",
    "                        datalabel[feature0].append(y)\n",
    "                        datalabel[feature1].append(y)\n",
    "                        datadict[feature0].append(signals0[start:end])\n",
    "                        datadict[feature1].append(signals1[start:end])\n",
    "\n",
    "                    annSymbol = ann.symbol\n",
    "\n",
    "                    if len(annSymbol) == 1 and (annSymbol[0] in classes):\n",
    "                        to_dict(annSymbol[0])\n",
    "\n",
    "    dataprocess()\n",
    "\n",
    "    for feature in [\"MLII\", \"V1\"]:\n",
    "        datadict[feature] = np.array(datadict[feature])\n",
    "        datalabel[feature] = np.array(datalabel[feature])\n",
    "\n",
    "    import deepdish as dd\n",
    "\n",
    "    \n",
    "    dd.io.save(datasetname, datadict)\n",
    "    dd.io.save(labelsname, datalabel)\n",
    "\n",
    "\n",
    "def main(config):\n",
    "    preprocess(config.split)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config = get_config()\n",
    "    main(config)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
